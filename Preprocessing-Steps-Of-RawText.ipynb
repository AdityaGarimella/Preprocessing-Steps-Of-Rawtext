{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import PyDictionary\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u>READING DATA</u></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AmazonLawnAndGardenReviews.csv',encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful__001</th>\n",
       "      <th>helpful__002</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Carter H \"1amazonreviewer@gmail . com\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Good USA company that stands behind their prod...</td>\n",
       "      <td>4</td>\n",
       "      <td>Great Hoses</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>06 21, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A32JCI4AK2JTTG</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Darryl Bennett \"Fuzzy342\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a high quality 8 ply hose. I have had ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...</td>\n",
       "      <td>1402272000</td>\n",
       "      <td>06 9, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                            reviewerName  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674  Carter H \"1amazonreviewer@gmail . com\"   \n",
       "1  A32JCI4AK2JTTG  B00002N674               Darryl Bennett \"Fuzzy342\"   \n",
       "\n",
       "   helpful__001  helpful__002  \\\n",
       "0             4             4   \n",
       "1             0             0   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Good USA company that stands behind their prod...        4   \n",
       "1  This is a high quality 8 ply hose. I have had ...        5   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                        Great Hoses      1308614400   \n",
       "1  Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...      1402272000   \n",
       "\n",
       "    reviewTime  \n",
       "0  06 21, 2011  \n",
       "1   06 9, 2014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful__001', 'helpful__002',\n",
       "       'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u>UTILITIES FUNCTIONS FOR TEXT PREPROCESSING</u></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_URLs(x):\n",
    "    x = x.split(' ')\n",
    "    x = [i for i in x if not len(re.findall(r'[\\w\\.-]+@[\\w\\.-]+',i))]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "def tokenizing(x):\n",
    "    return nltk.tokenize.word_tokenize(x)\n",
    "def stopwords(x):\n",
    "    stop_words=nltk.corpus.stopwords.words('english')\n",
    "    x=[i for i in x if i not in stop_words]\n",
    "    return x\n",
    "def Lemmatization(x):\n",
    "    lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "    x = [ lemmatizer.lemmatize(i) for i in x]\n",
    "    return x\n",
    "def Remove_numbers(x):\n",
    "    x = [re.sub('[^A-Z,a-z]+','',i) for i in x]\n",
    "    x = ' '.join(x).lower()\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u>FUNCTIONS TO USE FURTHER</u></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "\n",
    "    x = Remove_URLs(x)\n",
    "    x = tokenizing(x)\n",
    "    x = stopwords(x)\n",
    "    x = Lemmatization(x)\n",
    "    x = Remove_numbers(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good usa company that stands behind their products  i have had to warranty two hoses and they send replacements right out to you  i had one burst after awhile , you could see it buldge for weeks before it went so no suprises  the other one was winter related as i am bad and leave them out most of the time  highly reccomend  note the hundred footer is heavy and like wresting an anaconda when its time to put away , but it does have a far reach '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.reviewText\n",
    "Remove_numbers(tokenizing(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample text before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good USA company that stands behind their products. I have had to warranty two hoses and they send replacements right out to you. I had one burst after awhile, you could see it buldge for weeks before it went so no suprises. The other one was winter related as I am bad and leave them out most of the time. Highly reccomend. Note the hundred footer is heavy and like wresting an anaconda when its time to put away, but it does have a far reach.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=list(df.reviewText)\n",
    "df.reviewText[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample text after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good usa company stand behind product  i warranty two hose send replacement right  i one burst awhile , could see buldge week went suprises  the one winter related i bad leave time  highly reccomend  note hundred footer heavy like wresting anaconda time put away , far reach '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df.reviewText[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing all review texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Preprocess_Review'] =  df.reviewText.apply(lambda x: preprocess(x) if isinstance(x,str) else ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u>FEATURE ENGINEERING</u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting feature words from the reviews text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Word_set = set()\n",
    "for i in df.Preprocess_Review:\n",
    "    Word_set |= set(nltk.tokenize.word_tokenize(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of speech tagging to differentiate the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_tags = pd.DataFrame(nltk.pos_tag(list(Word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pricepoints</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gettinginstallation</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>withtrapit</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonautumn</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openerthe</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0    1\n",
       "0          pricepoints  NNS\n",
       "1  gettinginstallation   NN\n",
       "2           withtrapit  VBP\n",
       "3            nonautumn   IN\n",
       "4            openerthe   JJ"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of abbreivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNS', 'NN', 'VBP', 'IN', 'JJ', 'VBN', 'RB', 'VBD', 'VBG', 'NNP',\n",
       "       'VBZ', 'VB', 'JJS', 'WRB', 'DT', 'WP', 'JJR', 'CC', 'RP', 'FW',\n",
       "       'RBR', 'EX', 'MD', 'CD', 'PRP', 'PRP$', 'WDT', 'PDT', 'RBS', 'TO',\n",
       "       'WP$', ','], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_tags[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    CC | Coordinating conjunction |\n",
    "    CD | Cardinal number |\n",
    "    DT | Determiner |\n",
    "    EX | Existential there |\n",
    "    FW | Foreign word |\n",
    "    IN | Preposition or subordinating conjunction |\n",
    "    JJ | Adjective |\n",
    "    JJR | Adjective, comparative |\n",
    "    JJS | Adjective, superlative |\n",
    "    LS | List item marker |\n",
    "    MD | Modal |\n",
    "    NN | Noun, singular or mass |\n",
    "    NNS | Noun, plural |\n",
    "    NNP | Proper noun, singular |\n",
    "    NNPS | Proper noun, plural |\n",
    "    PDT | Predeterminer |\n",
    "    POS | Possessive ending |\n",
    "    PRP | Personal pronoun |\n",
    "    PRP$ | Possessive pronoun |\n",
    "    RB | Adverb |\n",
    "    RBR | Adverb, comparative |\n",
    "    RBS | Adverb, superlative |\n",
    "    RP | Particle |\n",
    "    SYM | Symbol |\n",
    "    TO | to |\n",
    "    UH | Interjection |\n",
    "    VB | Verb, base form |\n",
    "    VBD | Verb, past tense |\n",
    "    VBG | Verb, gerund or present participle |\n",
    "    VBN | Verb, past participle |\n",
    "    VBP | Verb, non-3rd person singular present |\n",
    "    VBZ | Verb, 3rd person singular present |\n",
    "    WDT | Wh-determiner |\n",
    "    WP | Wh-pronoun |\n",
    "    WP$ | Possessive wh-pronoun |\n",
    "    WRB | Wh-adverb |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the words which gives meaning out of sentence (verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words_verbs = Word_tags[Word_tags[1].isin(['VB','VBP','VBN','VBZ','RB'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>withtrapit</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>overtorqued</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reloadsunfortunately</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thenoverall</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lubricated</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0    1\n",
       "2             withtrapit  VBP\n",
       "5            overtorqued  VBN\n",
       "7   reloadsunfortunately   RB\n",
       "18           thenoverall  VBP\n",
       "20            lubricated  VBN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words_verbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful__001</th>\n",
       "      <th>helpful__002</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>Preprocess_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Carter H \"1amazonreviewer@gmail . com\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Good USA company that stands behind their prod...</td>\n",
       "      <td>4</td>\n",
       "      <td>Great Hoses</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>06 21, 2011</td>\n",
       "      <td>good usa company stand behind product  i warra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A32JCI4AK2JTTG</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Darryl Bennett \"Fuzzy342\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a high quality 8 ply hose. I have had ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...</td>\n",
       "      <td>1402272000</td>\n",
       "      <td>06 9, 2014</td>\n",
       "      <td>this high quality  ply hose  i good luck gilmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N0P5AAMP6XD2</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>H B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>It's probably one of the best hoses I've ever ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Very satisfied!</td>\n",
       "      <td>1336176000</td>\n",
       "      <td>05 5, 2012</td>\n",
       "      <td>it s probably one best hose i ve ever hadpro s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                            reviewerName  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674  Carter H \"1amazonreviewer@gmail . com\"   \n",
       "1  A32JCI4AK2JTTG  B00002N674               Darryl Bennett \"Fuzzy342\"   \n",
       "2  A3N0P5AAMP6XD2  B00002N674                                     H B   \n",
       "\n",
       "   helpful__001  helpful__002  \\\n",
       "0             4             4   \n",
       "1             0             0   \n",
       "2             2             3   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Good USA company that stands behind their prod...        4   \n",
       "1  This is a high quality 8 ply hose. I have had ...        5   \n",
       "2  It's probably one of the best hoses I've ever ...        4   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                        Great Hoses      1308614400   \n",
       "1  Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...      1402272000   \n",
       "2                                    Very satisfied!      1336176000   \n",
       "\n",
       "    reviewTime                                  Preprocess_Review  \n",
       "0  06 21, 2011  good usa company stand behind product  i warra...  \n",
       "1   06 9, 2014  this high quality  ply hose  i good luck gilmo...  \n",
       "2   05 5, 2012  it s probably one best hose i ve ever hadpro s...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good usa company stand behind product  i warranty two hose send replacement right  i one burst awhile , could see buldge week went suprises  the one winter related i bad leave time  highly reccomend  note hundred footer heavy like wresting anaconda time put away , far reach '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Preprocess_Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warranty', 'VBP'),\n",
       " ('send', 'VBP'),\n",
       " ('see', 'VB'),\n",
       " ('suprises', 'VBZ'),\n",
       " ('related', 'VBN'),\n",
       " ('leave', 'VBP'),\n",
       " ('highly', 'RB'),\n",
       " ('footer', 'RB'),\n",
       " ('away', 'RB'),\n",
       " ('far', 'RB')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in nltk.pos_tag(nltk.tokenize.word_tokenize(df.Preprocess_Review[0])) if i[1] in ['VB','VBP','VBZ','RB','VBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnise preprocess verbs of each review sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def func(x):\n",
    "    tokens = nltk.pos_tag(nltk.tokenize.word_tokenize(x))\n",
    "    verbs = [i for i in tokens if i[1] in ['VB','VBP','VBZ','RB','VBN']]\n",
    "    return verbs\n",
    "df['Verbs'] = df.Preprocess_Review.apply(lambda x : func(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Word categories to differentiate Nouns and Pronouns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.corpus.brown.categories()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.corpus.brown.words(categories='adventure')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.corpus.brown.categories()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.corpus.brown.words(categories='adventure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regular Expressions in Preprocessing Raw Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good USA company that stands behind their products. I have had to warranty two hoses and they send replacements right out to you. I had one burst after awhile, you could see it buldge for weeks before it went so no suprises. The other one was winter related as I am bad and leave them out most of the time. Highly reccomend. Note the hundred footer is heavy and like wresting an anaconda when its time to put away, but it does have a far reach.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all occurances of Required word <B> \"out\" </B> in Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out', 'out']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[o][u][t]',x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all <B> Integers </B> of Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98.4', '4343', '32.33', '343.0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = x[0]+'98.4   34   4343  32.33 343.0'\n",
    "re.findall(r'\\d+.\\d+',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all words which are ending with <B> 'ge' </B> in retrieving in <B> Contineous verbs</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buldge']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in nltk.tokenize.word_tokenize(x[0]) if re.search(r'ge$',w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda function in converting all words to <B> lower case</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pricepoints',\n",
       " 'gettinginstallation',\n",
       " 'withtrapit',\n",
       " 'nonautumn',\n",
       " 'openerthe',\n",
       " 'overtorqued',\n",
       " 'readymixed',\n",
       " 'reloadsunfortunately',\n",
       " 'fearof',\n",
       " 'carried',\n",
       " 'oneupdate',\n",
       " 'cognitive',\n",
       " 'humongous',\n",
       " 'somedayit',\n",
       " 'ironmetal',\n",
       " 'bubbler',\n",
       " 'whole',\n",
       " 'chips',\n",
       " 'thenoverall',\n",
       " 'fragility',\n",
       " 'lubricated',\n",
       " 'uphave',\n",
       " 'motif',\n",
       " 'induce',\n",
       " 'sprays',\n",
       " 'inchesi',\n",
       " 'blew',\n",
       " 'deployed',\n",
       " 'imploring',\n",
       " 'restricter',\n",
       " 'goodie',\n",
       " 'capacity',\n",
       " 'smokepaddle',\n",
       " 'multihour',\n",
       " 'onehandle',\n",
       " 'gardenshrubsetc',\n",
       " 'zinnias',\n",
       " 'triggerdo',\n",
       " 'cultivatortilleri',\n",
       " 'winnerupdate',\n",
       " 'litter',\n",
       " 'iwill',\n",
       " 'respectedif',\n",
       " 'returnedlooking',\n",
       " 'sizeheat',\n",
       " 'hav',\n",
       " 'unpainted',\n",
       " 'bottomline',\n",
       " 'irregularity',\n",
       " 'crawler',\n",
       " 'cropsthis',\n",
       " 'testedhere',\n",
       " 'global',\n",
       " 'buzy',\n",
       " 'ka',\n",
       " 'eel',\n",
       " 'smooththe',\n",
       " 'wiresgas',\n",
       " 'conflicting',\n",
       " 'teething',\n",
       " 'bay',\n",
       " 'vigorouslythese',\n",
       " 'recommendation',\n",
       " 'pronged',\n",
       " 'sunpros',\n",
       " 'treesoverall',\n",
       " 'freethe',\n",
       " 'huh',\n",
       " 'gelbait',\n",
       " 'vibrationsound',\n",
       " 'lest',\n",
       " 'investmentupdate',\n",
       " 'comfortablecontrols',\n",
       " 'remained',\n",
       " 'receives',\n",
       " 'seedchina',\n",
       " 'noseeum',\n",
       " 'plenty',\n",
       " 'lengthen',\n",
       " 'unperturbed',\n",
       " 'problemsgood',\n",
       " 'woodchuckthe',\n",
       " 'then',\n",
       " 'dissipated',\n",
       " 'greened',\n",
       " 'clamshelli',\n",
       " 'whatsoever',\n",
       " 'fiction',\n",
       " 'egret',\n",
       " 'removed',\n",
       " 'extractthe',\n",
       " 'disappearing',\n",
       " 'frontoverall',\n",
       " 'dontthese',\n",
       " 'applicationi',\n",
       " 'chondroitin',\n",
       " 'gee',\n",
       " 'populationthere',\n",
       " 'recommendations',\n",
       " 'conservative',\n",
       " 'involvedthe',\n",
       " 'snackalso',\n",
       " 'suprisingly',\n",
       " 'weightless',\n",
       " 'oxalis',\n",
       " 'wiresthis',\n",
       " 'anecdotal',\n",
       " 'gasketed',\n",
       " 'central',\n",
       " 'starsoverall',\n",
       " 'temporarymaybe',\n",
       " 'twirlasquirrel',\n",
       " 'proclaiming',\n",
       " 'corded',\n",
       " 'futile',\n",
       " 'nibbling',\n",
       " 'galore',\n",
       " 'attachable',\n",
       " 'frequentlythe',\n",
       " 'inconsistently',\n",
       " 'untreated',\n",
       " 'convential',\n",
       " 'semifull',\n",
       " 'shivver',\n",
       " 'divet',\n",
       " 'typeslocations',\n",
       " 'rancher',\n",
       " 'contactagain',\n",
       " 'installthey',\n",
       " 'betterbuilt',\n",
       " 'leafsthe',\n",
       " 'rejoice',\n",
       " 'tended',\n",
       " 'rosegarden',\n",
       " 'springthese',\n",
       " 'crystaline',\n",
       " 'flakey',\n",
       " 'surprisedpros',\n",
       " 'sanitarysafe',\n",
       " 'effectivelythe',\n",
       " 'crittersit',\n",
       " 'pplec',\n",
       " 'echinacea',\n",
       " 'weeping',\n",
       " 'objection',\n",
       " 'lumbar',\n",
       " 'prejudiced',\n",
       " 'mosquitosthis',\n",
       " 'thatthis',\n",
       " 'operationsone',\n",
       " 'undamagedi',\n",
       " 'minutesif',\n",
       " 'metaltype',\n",
       " 'laminating',\n",
       " 'empting',\n",
       " 'gasoperated',\n",
       " 'crotchet',\n",
       " 'positionnow',\n",
       " 'prohibited',\n",
       " 'before',\n",
       " 'proofthe',\n",
       " 'listed',\n",
       " 'spit',\n",
       " 'poweri',\n",
       " 'neighbors',\n",
       " 'holdsafe',\n",
       " 'perfectsetting',\n",
       " 'bladeon',\n",
       " 'ovalshaped',\n",
       " 'baaaack',\n",
       " 'sense',\n",
       " 'busting',\n",
       " 'treeedit',\n",
       " 'unsuspecting',\n",
       " 'basicallly',\n",
       " 'earlierthe',\n",
       " 'positionsthe',\n",
       " 'staggered',\n",
       " 'boardroom',\n",
       " 'ringcobraco',\n",
       " 'money',\n",
       " 'complicatedi',\n",
       " 'snipped',\n",
       " 'streaked',\n",
       " 'stairway',\n",
       " 'overzealous',\n",
       " 'counterintuitive',\n",
       " 'ambitious',\n",
       " 'everyone',\n",
       " 'streamlined',\n",
       " 'outofsite',\n",
       " 'wellseated',\n",
       " 'farmstead',\n",
       " 'androids',\n",
       " 'baitit',\n",
       " 'cambodia',\n",
       " 'famousin',\n",
       " 'gripping',\n",
       " 'rusti',\n",
       " 'partsproducts',\n",
       " 'onpart',\n",
       " 'splice',\n",
       " 'roominess',\n",
       " 'th',\n",
       " 'overfertilizedthe',\n",
       " 'peeled',\n",
       " 'favily',\n",
       " 'constabularywithout',\n",
       " 'amp',\n",
       " 'speciesthe',\n",
       " 'warrantymay',\n",
       " 'heavierlarger',\n",
       " 'icyslushy',\n",
       " 'nozzlewarrantygilmour',\n",
       " 'denigrate',\n",
       " 'needsfirst',\n",
       " 'misbehaving',\n",
       " 'behemoth',\n",
       " 'modeli',\n",
       " 'additionfinger',\n",
       " 'weighty',\n",
       " 'tomotaoes',\n",
       " 'gardner',\n",
       " 'hydroponicist',\n",
       " 'fixedhecho',\n",
       " 'month',\n",
       " 'freshener',\n",
       " 'reseed',\n",
       " 'complaints',\n",
       " 'capcons',\n",
       " 'beer',\n",
       " 'pace',\n",
       " 'electic',\n",
       " 'gardening',\n",
       " 'regulars',\n",
       " 'countrythis',\n",
       " 'arg',\n",
       " 'fullgrown',\n",
       " 'onceinawhile',\n",
       " 'mdf',\n",
       " 'foragelike',\n",
       " 'coveri',\n",
       " 'raised',\n",
       " 'informationnow',\n",
       " 'halfcharbroil',\n",
       " 'scrapsized',\n",
       " 'pots',\n",
       " 'testrun',\n",
       " 'courtesy',\n",
       " 'failsafe',\n",
       " 'quitemiffed',\n",
       " 'folly',\n",
       " 'clipsfor',\n",
       " 'snakeswhat',\n",
       " 'awesomethe',\n",
       " 'tryingthis',\n",
       " 'upreapply',\n",
       " 'barreltype',\n",
       " 'nooskinooski',\n",
       " 'helpupdate',\n",
       " 'trailing',\n",
       " 'plug',\n",
       " 'badwhen',\n",
       " 'tension',\n",
       " 'chippys',\n",
       " 'impresive',\n",
       " 'scouting',\n",
       " 'thecustom',\n",
       " 'sillyeasy',\n",
       " 'withguide',\n",
       " 'seeping',\n",
       " 'northwet',\n",
       " 'reviewsthe',\n",
       " 'nightperformancewise',\n",
       " 'swapping',\n",
       " 'pilfer',\n",
       " 'solidlybuilt',\n",
       " 'disadvantages',\n",
       " 'chlorinator',\n",
       " 'penetrating',\n",
       " 'backupall',\n",
       " 'watertight',\n",
       " 'wayon',\n",
       " 'enoughthanks',\n",
       " 'fullthe',\n",
       " 'prefolded',\n",
       " 'hothouseheatmat',\n",
       " 'sameyou',\n",
       " 'clackettyclack',\n",
       " 'recordbreaking',\n",
       " 'craftmans',\n",
       " 'timetips',\n",
       " 'wetwould',\n",
       " 'hummingbird',\n",
       " 'insongbird',\n",
       " 'admits',\n",
       " 'dynoglo',\n",
       " 'installed',\n",
       " 'yahoo',\n",
       " 'sharpenedthe',\n",
       " 'waitingupdate',\n",
       " 'scissorsbypass',\n",
       " 'apparently',\n",
       " 'smoother',\n",
       " 'elsethe',\n",
       " 'wrsweeney',\n",
       " 'barelythere',\n",
       " 'startfor',\n",
       " 'coloryou',\n",
       " 'glassthe',\n",
       " 'equally',\n",
       " 'tootsie',\n",
       " 'repetition',\n",
       " 'reliable',\n",
       " 'pawsclass',\n",
       " 'refill',\n",
       " 'hows',\n",
       " 'cycled',\n",
       " 'couldi',\n",
       " 'splurge',\n",
       " 'senses',\n",
       " 'tomatoesfour',\n",
       " 'pictorialtext',\n",
       " 'handgrip',\n",
       " 'bothi',\n",
       " 'cordura',\n",
       " 'apprehension',\n",
       " 'ionlithium',\n",
       " 'disingenuous',\n",
       " 'dayso',\n",
       " 'spoton',\n",
       " 'badger',\n",
       " 'retrofit',\n",
       " 'orthoboric',\n",
       " 'tutorial',\n",
       " 'capsaisin',\n",
       " 'ripoff',\n",
       " 'doest',\n",
       " 'deterrentthe',\n",
       " 'muchloved',\n",
       " 'cannister',\n",
       " 'hop',\n",
       " 'shishkabobs',\n",
       " 'looping',\n",
       " 'egb',\n",
       " 'shippingups',\n",
       " 'knowingly',\n",
       " 'nowanother',\n",
       " 'windowi',\n",
       " 'reelcylinder',\n",
       " 'pix',\n",
       " 'funkybut',\n",
       " 'nonhazardous',\n",
       " 'spell',\n",
       " 'ratsmice',\n",
       " 'augment',\n",
       " 'pinpoint',\n",
       " 'calledspeaking',\n",
       " 'connivence',\n",
       " 'daydid',\n",
       " 'shadowy',\n",
       " 'obligation',\n",
       " 'tha',\n",
       " 'shutout',\n",
       " 'phenomenalthe',\n",
       " 'loser',\n",
       " 'failalso',\n",
       " 'slit',\n",
       " 'rarer',\n",
       " 'stabbing',\n",
       " 'doso',\n",
       " 'nicad',\n",
       " 'openandclose',\n",
       " 'pov',\n",
       " 'setting',\n",
       " 'neutral',\n",
       " 'mixturebait',\n",
       " 'wetter',\n",
       " 'boxbulb',\n",
       " 'soilwhen',\n",
       " 'irresistible',\n",
       " 'visuals',\n",
       " 'sanded',\n",
       " 'suffocate',\n",
       " 'resistantif',\n",
       " 'indiana',\n",
       " 'pac',\n",
       " 'buyer',\n",
       " 'iike',\n",
       " 'productali',\n",
       " 'right',\n",
       " 'goodthanks',\n",
       " 'triggerthe',\n",
       " 'zeroto',\n",
       " 'guardoverall',\n",
       " 'workamazon',\n",
       " 'seedlingsi',\n",
       " 'deeti',\n",
       " 'enrironments',\n",
       " 'topbottom',\n",
       " 'hiccup',\n",
       " 'amazingmy',\n",
       " 'departure',\n",
       " 'plugsthe',\n",
       " 'blistered',\n",
       " 'homeschool',\n",
       " 'basementwe',\n",
       " 'explicitly',\n",
       " 'timeabout',\n",
       " 'browsed',\n",
       " 'tpt',\n",
       " 'drinkyou',\n",
       " 'drops',\n",
       " 'attentionsthis',\n",
       " 'yer',\n",
       " 'factscontradictions',\n",
       " 'hemocyanin',\n",
       " 'greased',\n",
       " 'powerfulgoodall',\n",
       " 'hvae',\n",
       " 'lowkeyburt',\n",
       " 'timerto',\n",
       " 'minifruit',\n",
       " 'neededit',\n",
       " 'programpayment',\n",
       " 'dainty',\n",
       " 'selling',\n",
       " 'theportable',\n",
       " 'manufactureras',\n",
       " 'upped',\n",
       " 'wayit',\n",
       " 'nano',\n",
       " 'historyi',\n",
       " 'grdnerkit',\n",
       " 'temptation',\n",
       " 'foliage',\n",
       " 'talc',\n",
       " 'stakesto',\n",
       " 'calciumthe',\n",
       " 'fighting',\n",
       " 'wellknown',\n",
       " 'preferance',\n",
       " 'tbsp',\n",
       " 'goodthere',\n",
       " 'coversbar',\n",
       " 'practicei',\n",
       " 'amazonpinzon',\n",
       " 'racoonn',\n",
       " 'drovesso',\n",
       " 'reappeared',\n",
       " 'theywork',\n",
       " 'foyer',\n",
       " 'frequency',\n",
       " 'failuresthe',\n",
       " 'pig',\n",
       " 'needsrecommended',\n",
       " 'criticizing',\n",
       " 'shift',\n",
       " 'airplane',\n",
       " 'mush',\n",
       " 'crapinoly',\n",
       " 'amber',\n",
       " 'flowerpot',\n",
       " 'openingclosing',\n",
       " 'participation',\n",
       " 'raccoonhavahart',\n",
       " 'backlap',\n",
       " 'batteriesupdate',\n",
       " 'grillingthis',\n",
       " 'dearly',\n",
       " 'daffodil',\n",
       " 'roomall',\n",
       " 'choiceif',\n",
       " 'nightmare',\n",
       " 'inflatedthe',\n",
       " 'simplicity',\n",
       " 'completelywhile',\n",
       " 'benzalkonium',\n",
       " 'haussmann',\n",
       " 'tickled',\n",
       " 'casing',\n",
       " 'metalplastic',\n",
       " 'pretty',\n",
       " 'therethere',\n",
       " 'washi',\n",
       " 'form',\n",
       " 'patternsmaintenance',\n",
       " 'gratification',\n",
       " 'lothighly',\n",
       " 'insisted',\n",
       " 'spinbased',\n",
       " 'firing',\n",
       " 'hopingas',\n",
       " 'semidisposable',\n",
       " 'document',\n",
       " 'hardcompacted',\n",
       " 'blithely',\n",
       " 'binge',\n",
       " 'bob',\n",
       " 'concocted',\n",
       " 'hint',\n",
       " 'disregarded',\n",
       " 'walltwo',\n",
       " 'catch',\n",
       " 'feederwait',\n",
       " 'orderd',\n",
       " 'brightest',\n",
       " 'midatlantic',\n",
       " 'contributes',\n",
       " 'sickening',\n",
       " 'vein',\n",
       " 'introduces',\n",
       " 'fronton',\n",
       " 'effetiveness',\n",
       " 'togetherno',\n",
       " 'spike',\n",
       " 'dripped',\n",
       " 'giveto',\n",
       " 'moreafter',\n",
       " 'connecter',\n",
       " 'amazonthe',\n",
       " 'areaif',\n",
       " 'sprayerps',\n",
       " 'differs',\n",
       " 'mepower',\n",
       " 'mostlybefore',\n",
       " 'seedsscotts',\n",
       " 'ultimately',\n",
       " 'wayas',\n",
       " 'identified',\n",
       " 'preseeded',\n",
       " 'whatsoeverthe',\n",
       " 'lowerdon',\n",
       " 'doneyes',\n",
       " 'overtime',\n",
       " 'expections',\n",
       " 'nada',\n",
       " 'atas',\n",
       " 'lubrication',\n",
       " 'chip',\n",
       " 'periodi',\n",
       " 'smokeflavor',\n",
       " 'listened',\n",
       " 'nurseryi',\n",
       " 'shortground',\n",
       " 'kneeler',\n",
       " 'supply',\n",
       " 'toofourth',\n",
       " 'delightful',\n",
       " 'sprayerupdate',\n",
       " 'mortgage',\n",
       " 'impressiveoverall',\n",
       " 'cakerequires',\n",
       " 'lube',\n",
       " 'utilize',\n",
       " 'disentegrate',\n",
       " 'caughtand',\n",
       " 'precharged',\n",
       " 'wane',\n",
       " 'prepare',\n",
       " 'lawngardening',\n",
       " 'designedhere',\n",
       " 'nongaraged',\n",
       " 'startedthe',\n",
       " 'cordeven',\n",
       " 'oerfect',\n",
       " 'ticks',\n",
       " 'neckshoulderback',\n",
       " 'startedi',\n",
       " 'rectangular',\n",
       " 'wager',\n",
       " 'mainly',\n",
       " 'resultsdeer',\n",
       " 'setfast',\n",
       " 'traction',\n",
       " 'flared',\n",
       " 'hotthe',\n",
       " 'pheremone',\n",
       " 'battered',\n",
       " 'ho',\n",
       " 'miniture',\n",
       " 'meaningful',\n",
       " 'preformed',\n",
       " 'overflow',\n",
       " 'directsew',\n",
       " 'eitherthis',\n",
       " 'widethe',\n",
       " 'attractiveeasy',\n",
       " 'benefitted',\n",
       " 'gibbet',\n",
       " 'affiliated',\n",
       " 'brushbe',\n",
       " 'shriveled',\n",
       " 'chainsawfrom',\n",
       " 'chipmunk',\n",
       " 'daykeep',\n",
       " 'garret',\n",
       " 'donating',\n",
       " 'recycling',\n",
       " 'hugh',\n",
       " 'instructionspros',\n",
       " 'pruning',\n",
       " 'weekskeep',\n",
       " 'gg',\n",
       " 'tacoma',\n",
       " 'graveled',\n",
       " 'mustget',\n",
       " 'finetune',\n",
       " 'saew',\n",
       " 'refillable',\n",
       " 'replacemotomco',\n",
       " 'farmers',\n",
       " 'pepperspray',\n",
       " 'cake',\n",
       " 'mosquitoesi',\n",
       " 'neighborhoodthis',\n",
       " 'manicured',\n",
       " 'niftydetractions',\n",
       " 'riddenfor',\n",
       " 'pv',\n",
       " 'instability',\n",
       " 'timesalthough',\n",
       " 'algaecide',\n",
       " 'timeoverall',\n",
       " 'trappingwe',\n",
       " 'wacker',\n",
       " 'songbird',\n",
       " 'mr',\n",
       " 'waist',\n",
       " 'piipe',\n",
       " 'seedsclones',\n",
       " 'aloneso',\n",
       " 'indoor',\n",
       " 'ahydrofarm',\n",
       " 'refreshment',\n",
       " 'openingsbased',\n",
       " 'thoughanyway',\n",
       " 'ages',\n",
       " 'hedgeclipping',\n",
       " 'issuea',\n",
       " 'touchedi',\n",
       " 'wireless',\n",
       " 'atbig',\n",
       " 'attacts',\n",
       " 'lightweightb',\n",
       " 'indoctrination',\n",
       " 'diagraminstructions',\n",
       " 'potfiller',\n",
       " 'difficut',\n",
       " 'skirting',\n",
       " 'footlong',\n",
       " 'stench',\n",
       " 'dustcatcher',\n",
       " 'fllowing',\n",
       " 'trashbin',\n",
       " 'diffusing',\n",
       " 'attractiveas',\n",
       " 'screwdriverpro',\n",
       " 'screwthere',\n",
       " 'shellsif',\n",
       " 'snot',\n",
       " 'drinkingthe',\n",
       " 'furniturenote',\n",
       " 'guideline',\n",
       " 'tortillasand',\n",
       " 'laughable',\n",
       " 'robins',\n",
       " 'rough',\n",
       " 'keeps',\n",
       " 'nyc',\n",
       " 'blogwebsite',\n",
       " 'gardeners',\n",
       " 'itplus',\n",
       " 'unmolestedi',\n",
       " 'feederunlike',\n",
       " 'rectilinear',\n",
       " 'invaluable',\n",
       " 'etcenter',\n",
       " 'appliancethe',\n",
       " 'tier',\n",
       " 'scenario',\n",
       " 'regimen',\n",
       " 'soilsafety',\n",
       " 'underside',\n",
       " 'hill',\n",
       " 'soundness',\n",
       " 'rating',\n",
       " 'erings',\n",
       " 'initiative',\n",
       " 'worksupdate',\n",
       " 'tis',\n",
       " 'powerful',\n",
       " 'perfectionist',\n",
       " 'difficultyi',\n",
       " 'stomped',\n",
       " 'inferiorpoor',\n",
       " 'bumps',\n",
       " 'frickin',\n",
       " 'effortstrain',\n",
       " 'lifelong',\n",
       " 'wallsthis',\n",
       " 'swoopsthe',\n",
       " 'feederounce',\n",
       " 'beforehand',\n",
       " 'plusand',\n",
       " 'nonconductive',\n",
       " 'bakes',\n",
       " 'visibly',\n",
       " 'springloaded',\n",
       " 'designing',\n",
       " 'hmocha',\n",
       " 'businessfrom',\n",
       " 'virginia',\n",
       " 'goodlooking',\n",
       " 'noisesmy',\n",
       " 'tool',\n",
       " 'sanitize',\n",
       " 'sporting',\n",
       " 'zapped',\n",
       " 'bonusperhaps',\n",
       " 'ecycler',\n",
       " 'areanyway',\n",
       " 'reared',\n",
       " 'longthis',\n",
       " 'producthowever',\n",
       " 'ithink',\n",
       " 'unsoftened',\n",
       " 'sharpe',\n",
       " 'hilarity',\n",
       " 'holderit',\n",
       " 'onfree',\n",
       " 'weakling',\n",
       " 'overspray',\n",
       " 'groundit',\n",
       " 'muffin',\n",
       " 'determines',\n",
       " 'mosquitoesthe',\n",
       " 'tasted',\n",
       " 'nutbolt',\n",
       " 'problemsdurability',\n",
       " 'hook',\n",
       " 'firedoriginal',\n",
       " 'dislodges',\n",
       " 'tillers',\n",
       " 'garage',\n",
       " 'pitit',\n",
       " 'axehatchet',\n",
       " 'containersi',\n",
       " 'tenting',\n",
       " 'effectivity',\n",
       " 'brushpad',\n",
       " 'cloning',\n",
       " 'spools',\n",
       " 'sidewalk',\n",
       " 'facilitate',\n",
       " 'grave',\n",
       " 'adoptioneasy',\n",
       " 'weatherclimate',\n",
       " 'partswe',\n",
       " 'liston',\n",
       " 'choiceeasy',\n",
       " 'baitother',\n",
       " 'wellsome',\n",
       " 'upgood',\n",
       " 'notethey',\n",
       " 'fasten',\n",
       " 'fanning',\n",
       " 'partsthis',\n",
       " 'wellpositioned',\n",
       " 'nonused',\n",
       " 'rechargables',\n",
       " 'incentive',\n",
       " 'multicookers',\n",
       " 'desperately',\n",
       " 'pronto',\n",
       " 'fest',\n",
       " 'value',\n",
       " 'knowing',\n",
       " 'kitchenfor',\n",
       " 'eachall',\n",
       " 'reentry',\n",
       " 'attacker',\n",
       " 'explorer',\n",
       " 'holethat',\n",
       " 'happensso',\n",
       " 'sixpack',\n",
       " 'wickedly',\n",
       " 'potash',\n",
       " 'context',\n",
       " 'specimen',\n",
       " 'funnelthis',\n",
       " 'blackjust',\n",
       " 'feedersingredients',\n",
       " 'onebox',\n",
       " 'write',\n",
       " 'semiglobe',\n",
       " 'inviting',\n",
       " 'veteran',\n",
       " 'theseeasy',\n",
       " 'baitcomes',\n",
       " 'fineif',\n",
       " 'negativesthis',\n",
       " 'togetherlastly',\n",
       " 'homeso',\n",
       " 'viewi',\n",
       " 'pooled',\n",
       " 'marinated',\n",
       " 'louee',\n",
       " 'accuracy',\n",
       " 'caring',\n",
       " 'coke',\n",
       " 'timesetup',\n",
       " 'weirdbottom',\n",
       " 'yellowjacket',\n",
       " 'biodegradeable',\n",
       " 'tuneups',\n",
       " 'lightat',\n",
       " 'pacemaker',\n",
       " 'appian',\n",
       " 'plantes',\n",
       " 'downthe',\n",
       " 'verys',\n",
       " 'eventi',\n",
       " 'surpriseyou',\n",
       " 'dastardly',\n",
       " 'prudent',\n",
       " 'trayperch',\n",
       " 'novicewhen',\n",
       " 'reconfigured',\n",
       " 'notmy',\n",
       " 'styleall',\n",
       " 'housethe',\n",
       " 'goof',\n",
       " 'hippo',\n",
       " 'conquered',\n",
       " 'tormented',\n",
       " 'unwanted',\n",
       " 'sliced',\n",
       " 'reservation',\n",
       " 'coneflower',\n",
       " 'sectioned',\n",
       " 'bagmulchside',\n",
       " 'submergethe',\n",
       " 'propanewe',\n",
       " 'cardnal',\n",
       " 'topped',\n",
       " 'eyesthe',\n",
       " 'repelled',\n",
       " 'organize',\n",
       " 'resetwhile',\n",
       " 'danger',\n",
       " 'air',\n",
       " 'goodbye',\n",
       " 'wallyworld',\n",
       " 'googled',\n",
       " 'hmm',\n",
       " 'replied',\n",
       " 'sprayif',\n",
       " 'interchangeable',\n",
       " 'shaking',\n",
       " 'blazing',\n",
       " 'subscribe',\n",
       " 'inclusion',\n",
       " 'electrocute',\n",
       " 'upsetting',\n",
       " 'wound',\n",
       " 'thehavahart',\n",
       " 'seenthis',\n",
       " 'goldfinches',\n",
       " 'upheld',\n",
       " 'easierthen',\n",
       " 'pistollike',\n",
       " 'quivering',\n",
       " 'stalledmy',\n",
       " 'notified',\n",
       " 'calked',\n",
       " 'areasbecause',\n",
       " 'greatwhat',\n",
       " 'issueoverall',\n",
       " 'pay',\n",
       " 'thrip',\n",
       " 'lefty',\n",
       " 'crackling',\n",
       " 'perliteworks',\n",
       " 'bottompan',\n",
       " 'dustin',\n",
       " 'backit',\n",
       " 'chloride',\n",
       " 'animalshaped',\n",
       " 'shovelful',\n",
       " 'kg',\n",
       " 'rechargethe',\n",
       " 'whichy',\n",
       " 'carb',\n",
       " 'boardwalk',\n",
       " 'pawing',\n",
       " 'lemons',\n",
       " 'habitationknowing',\n",
       " 'lumber',\n",
       " 'distinction',\n",
       " 'hardache',\n",
       " 'wettip',\n",
       " 'sidewinder',\n",
       " 'decreasedfwiw',\n",
       " 'sunheat',\n",
       " 'surebtw',\n",
       " 'mink',\n",
       " 'occupier',\n",
       " 'cati',\n",
       " 'tje',\n",
       " 'hondaengine',\n",
       " 'fourhour',\n",
       " 'socket',\n",
       " 'activity',\n",
       " 'winningi',\n",
       " 'griddle',\n",
       " 'clam',\n",
       " 'tbar',\n",
       " 'havei',\n",
       " 'upsidedownit',\n",
       " 'scratchfadeoxidize',\n",
       " 'topaz',\n",
       " 'occurence',\n",
       " 'agrifab',\n",
       " 'admit',\n",
       " 'task',\n",
       " 'usehandle',\n",
       " 'insteadkonedog',\n",
       " 'asks',\n",
       " 'piecesfinal',\n",
       " 'tasksthat',\n",
       " 'hammerwe',\n",
       " 'daythe',\n",
       " 'smore',\n",
       " 'aseemble',\n",
       " 'polymer',\n",
       " 'itemsthe',\n",
       " 'miniterrariumsurprise',\n",
       " 'usehighly',\n",
       " 'unwieldiness',\n",
       " 'nonenriched',\n",
       " 'ungreen',\n",
       " 'technicality',\n",
       " 'colored',\n",
       " 'breathe',\n",
       " 'analysis',\n",
       " 'roofing',\n",
       " 'weatheringit',\n",
       " 'wellblade',\n",
       " 'populate',\n",
       " 'fluidsparaffin',\n",
       " 'klatch',\n",
       " 'owned',\n",
       " 'reservoir',\n",
       " 'productperhaps',\n",
       " 'grubbing',\n",
       " 'messythere',\n",
       " 'victimas',\n",
       " 'dirtpollensludge',\n",
       " 'lightpretty',\n",
       " 'smokerpressure',\n",
       " 'decon',\n",
       " 'graphic',\n",
       " 'motherinlaw',\n",
       " 'insectsmost',\n",
       " 'planterpot',\n",
       " 'bricksthese',\n",
       " 'sizesome',\n",
       " 'itthose',\n",
       " 'plantingi',\n",
       " 'yearas',\n",
       " 'doubtless',\n",
       " 'retighten',\n",
       " 'zipping',\n",
       " 'vouch',\n",
       " 'settingneighborenvy',\n",
       " 'rankings',\n",
       " 'partly',\n",
       " 'lastsworks',\n",
       " 'greathint',\n",
       " 'pennythe',\n",
       " 'protectazaleas',\n",
       " 'highflow',\n",
       " 'hourblack',\n",
       " 'eleven',\n",
       " 'bitty',\n",
       " 'requiredoverall',\n",
       " 'ater',\n",
       " 'film',\n",
       " 'squirrelproofness',\n",
       " 'fasteri',\n",
       " 'atv',\n",
       " 'roadwith',\n",
       " 'diddo',\n",
       " 'blowersslight',\n",
       " 'attatchment',\n",
       " 'endquality',\n",
       " 'hblc',\n",
       " 'diligent',\n",
       " 'chive',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.lower(),Word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good USA company that stands behind their products. I have had to warranty two hoses and they send replacements right out to you. I had one burst after awhile, you could see it buldge for weeks before it went so no suprises. The other one was winter related as I am bad and leave them out most of the time. Highly reccomend. Note the hundred footer is heavy and like wresting an anaconda when its time to put away, but it does have a far reach.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all words of raw text which are in <B> length of 5 to 7 </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company',\n",
       " 'stands',\n",
       " 'behind',\n",
       " 'their',\n",
       " 'products',\n",
       " 'warranty',\n",
       " 'hoses',\n",
       " 'replacements',\n",
       " 'right',\n",
       " 'burst',\n",
       " 'after',\n",
       " 'awhile',\n",
       " 'could',\n",
       " 'buldge',\n",
       " 'weeks',\n",
       " 'before',\n",
       " 'suprises',\n",
       " 'other',\n",
       " 'winter',\n",
       " 'related',\n",
       " 'leave',\n",
       " 'Highly',\n",
       " 'reccomend',\n",
       " 'hundred',\n",
       " 'footer',\n",
       " 'heavy',\n",
       " 'wresting',\n",
       " 'anaconda']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in nltk.tokenize.word_tokenize(w) if re.search(r'\\w{5,7}$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting of all words which are in <B> length of 5 </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['their',\n",
       " 'hoses',\n",
       " 'right',\n",
       " 'burst',\n",
       " 'after',\n",
       " 'could',\n",
       " 'weeks',\n",
       " 'other',\n",
       " 'leave',\n",
       " 'heavy']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in nltk.tokenize.word_tokenize(w) if re.search(r'^[a-zA-F]{5}$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <B> Finding all occurances </B> of given word in raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out', 'out']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[o][u][t]',x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all words which are <b>Greater than length 3 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['probably',\n",
       " 'should',\n",
       " 'have',\n",
       " 'bought',\n",
       " 'something',\n",
       " 'bit',\n",
       " 'more',\n",
       " 'flexible',\n",
       " 'and',\n",
       " 'less',\n",
       " 'rugged',\n",
       " 'since',\n",
       " 'constantly',\n",
       " 'for',\n",
       " 'washing',\n",
       " 'cars',\n",
       " 'but',\n",
       " 'that',\n",
       " 'fault',\n",
       " 'not',\n",
       " 'product',\n",
       " 'fault']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = nltk.tokenize.word_tokenize(x[3])\n",
    "[w for w in wordlist if re.search('^[a-z]{3,}$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all the <b> Float values </b> of Raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98.4', '32.33', '343.0']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d+\\.\\d+', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(174, 176), match='it'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'[i][t]+',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for the all the required <B>combinations of words</B> which are with <B> ghi- 1st letter,mno-2nd letter,jlk-3rd letter,def-4th letter </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in nltk.tokenize.word_tokenize(x[0]) if re.search('^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Importing the words from NLTK repository of Corpus\n",
    "the words are tagged with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "a=nltk.corpus.brown.tagged_words(categories='news')[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 5580), (',', 5188), ('.', 4030), ('of', 2849), ('and', 2146)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words(categories='news'))\n",
    "fd.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional FreqDist to visualize the words of having <B> specified length condition</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Good', FreqDist({'JJ': 1})), ('USA', FreqDist({'NNP': 1})), ('company', FreqDist({'NN': 1})), ('that', FreqDist({'WDT': 1})), ('stands', FreqDist({'VBZ': 1})), ('behind', FreqDist({'IN': 1})), ('their', FreqDist({'PRP$': 1})), ('products', FreqDist({'NNS': 1})), ('.', FreqDist({'.': 6})), ('I', FreqDist({'PRP': 3})), ('have', FreqDist({'VBP': 1, 'VB': 1})), ('had', FreqDist({'VBN': 1, 'VBD': 1})), ('to', FreqDist({'TO': 3})), ('warranty', FreqDist({'VB': 1})), ('two', FreqDist({'CD': 1})), ('hoses', FreqDist({'NNS': 1})), ('and', FreqDist({'CC': 3})), ('they', FreqDist({'PRP': 1})), ('send', FreqDist({'VBP': 1})), ('replacements', FreqDist({'NNS': 1})), ('right', FreqDist({'RB': 1})), ('out', FreqDist({'IN': 1, 'RP': 1})), ('you', FreqDist({'PRP': 2})), ('one', FreqDist({'CD': 1, 'NN': 1})), ('burst', FreqDist({'NN': 1})), ('after', FreqDist({'IN': 1})), ('awhile', FreqDist({'NN': 1})), (',', FreqDist({',': 2})), ('could', FreqDist({'MD': 1})), ('see', FreqDist({'VB': 1})), ('it', FreqDist({'PRP': 3})), ('buldge', FreqDist({'VB': 1})), ('for', FreqDist({'IN': 1})), ('weeks', FreqDist({'NNS': 1})), ('before', FreqDist({'IN': 1})), ('went', FreqDist({'VBD': 1})), ('so', FreqDist({'RB': 1})), ('no', FreqDist({'DT': 1})), ('suprises', FreqDist({'NNS': 1})), ('The', FreqDist({'DT': 1})), ('other', FreqDist({'JJ': 1})), ('was', FreqDist({'VBD': 1})), ('winter', FreqDist({'RB': 1})), ('related', FreqDist({'VBN': 1})), ('as', FreqDist({'IN': 1})), ('am', FreqDist({'VBP': 1})), ('bad', FreqDist({'JJ': 1})), ('leave', FreqDist({'VB': 1})), ('them', FreqDist({'PRP': 1})), ('most', FreqDist({'JJS': 1})), ('of', FreqDist({'IN': 1})), ('the', FreqDist({'DT': 2})), ('time', FreqDist({'NN': 2})), ('Highly', FreqDist({'NNP': 1})), ('reccomend', FreqDist({'NN': 1})), ('Note', FreqDist({'VB': 1})), ('hundred', FreqDist({'CD': 1})), ('footer', FreqDist({'NN': 1})), ('is', FreqDist({'VBZ': 1})), ('heavy', FreqDist({'JJ': 1})), ('like', FreqDist({'IN': 1})), ('wresting', FreqDist({'VBG': 1})), ('an', FreqDist({'DT': 1})), ('anaconda', FreqDist({'NN': 1})), ('when', FreqDist({'WRB': 1})), ('its', FreqDist({'PRP$': 1})), ('put', FreqDist({'VB': 1})), ('away', FreqDist({'RP': 1})), ('but', FreqDist({'CC': 1})), ('does', FreqDist({'VBZ': 1})), ('a', FreqDist({'DT': 1})), ('far', FreqDist({'RB': 1})), ('reach', FreqDist({'NN': 1}))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.ConditionalFreqDist(nltk.corpus.brown.words(categories='news'))\n",
    "d =nltk.ConditionalFreqDist(nltk.pos_tag(nltk.tokenize.word_tokenize(x[0])))\n",
    "d.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ,    .   CC   CD   DT   IN   JJ  JJS   MD   NN  NNP  NNS  PRP PRP$   RB   RP   TO   VB  VBD  VBG  VBN  VBP  VBZ  WDT  WRB \n",
      "           ,    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "           .    0    6    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        Good    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "      Highly    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "           I    0    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        Note    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "         The    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         USA    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "           a    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       after    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          am    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0 \n",
      "          an    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "    anaconda    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         and    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          as    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        away    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      "      awhile    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         bad    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "      before    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "      behind    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "      buldge    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "       burst    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         but    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "     company    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       could    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        does    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "         far    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      "      footer    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         for    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         had    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0 \n",
      "        have    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    0 \n",
      "       heavy    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       hoses    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "     hundred    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          is    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "          it    0    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         its    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       leave    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "        like    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        most    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          no    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          of    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         one    0    0    0    1    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       other    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         out    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      "    products    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "         put    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "       reach    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "   reccomend    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "     related    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0 \n",
      "replacements    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       right    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      "         see    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "        send    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0 \n",
      "          so    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      "      stands    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "    suprises    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        that    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0 \n",
      "         the    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "       their    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        them    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        they    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        time    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "          to    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0    0    0    0    0    0 \n",
      "         two    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "    warranty    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "         was    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0 \n",
      "       weeks    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "        went    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0 \n",
      "        when    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1 \n",
      "      winter    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      "    wresting    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0 \n",
      "         you    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d.tabulate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(nltk.corpus.brown.tagged_words(categories='news')[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 AT    IN    JJ JJ-TL    NN NN-TL   NP$ NP-TL    NR   VBD \n",
      "    Atlanta's     0     0     0     0     0     0     1     0     0     0 \n",
      "       County     0     0     0     0     0     1     0     0     0     0 \n",
      "       Friday     0     0     0     0     0     0     0     0     1     0 \n",
      "       Fulton     0     0     0     0     0     0     0     1     0     0 \n",
      "        Grand     0     0     0     1     0     0     0     0     0     0 \n",
      "         Jury     0     0     0     0     0     1     0     0     0     0 \n",
      "          The     1     0     0     0     0     0     0     0     0     0 \n",
      "           an     1     0     0     0     0     0     0     0     0     0 \n",
      "     election     0     0     0     0     1     0     0     0     0     0 \n",
      "investigation     0     0     0     0     1     0     0     0     0     0 \n",
      "           of     0     1     0     0     0     0     0     0     0     0 \n",
      "      primary     0     0     0     0     1     0     0     0     0     0 \n",
      "     produced     0     0     0     0     0     0     0     0     0     1 \n",
      "       recent     0     0     1     0     0     0     0     0     0     0 \n",
      "         said     0     0     0     0     0     0     0     0     0     1 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cfd.tabulate()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.corpus.brown.tagged_sents(categories='news')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
